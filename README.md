# Simple-MCP: 智能用户查询系统

一个基于 MCP (Model Context Protocol) 和本地 Ollama 大模型的智能用户数据库查询系统。支持自然语言查询用户信息，通过 LLM 理解用户意图并调用相应工具获取数据。

## 📋 项目概述

这个项目演示了如何使用 MCP 协议连接本地大模型（Ollama qwen3:14b）与自定义数据库工具，实现智能的自然语言查询功能。用户可以用中文问题查询用户信息，系统会自动调用相应的数据库工具并返回结果。

**核心特性：**
- ✅ 基于 MCP 协议的工具调用框架
- ✅ 本地 Ollama 大模型支持（完全离线）
- ✅ 自然语言理解和意图识别
- ✅ 多条件灵活查询（支持 6 种查询参数）
- ✅ 完整的日志记录和可视化
- ✅ 两步式 LLM 处理流程

---

## 🔍 MCP 技术介绍

### 什么是 MCP？

**Model Context Protocol (MCP)** 是由 Anthropic 开发的开放标准协议，用于在 AI 应用和外部工具之间进行通信。它定义了一套标准的请求-响应格式，允许 LLM 无缝调用外部工具和数据源。

### MCP 的核心概念

1. **工具定义 (Tools)**: 服务器通过 MCP 向客户端广播可用的工具列表及其参数定义
2. **工具调用 (Tool Calls)**: 客户端通过 LLM 决策后调用工具，传递相应参数
3. **JSON-RPC 通信**: 使用 JSON-RPC 2.0 格式通过 stdio 进行消息交换
4. **会话管理**: 建立长连接会话，支持多次工具调用

### MCP 在本项目中的作用

```
用户输入 (自然语言)
    ↓
LLM 理解和决策
    ↓
MCP 工具调用 (query_users / get_user_by_id)
    ↓
数据库查询执行
    ↓
结果返回给 LLM
    ↓
LLM 生成最终答案
    ↓
用户获得结果
```

---

## 📁 项目结构

```
Simple-MCP/
├── mcp_server.py          # MCP 服务器，定义可用工具和数据库
├── client.py              # MCP 客户端，与 LLM 交互并调用工具
├── test_query_users.py    # 单元测试脚本，测试查询功能
├── requirements.txt       # Python 依赖
└── README.md              # 项目文档
```

### 核心文件说明

**mcp_server.py**
- 定义 13 个用户的数据库
- 实现两个 MCP 工具：
  - `query_users`: 多条件用户查询（支持 6 种参数）
  - `get_user_by_id`: 根据 ID 获取单个用户
- 使用 FastMCP 框架启动 MCP 服务器

**client.py**
- 连接本地 Ollama 模型 (qwen3:14b)
- 实现两阶段 LLM 处理：
  1. 工具决策：LLM 根据用户问题决定调用哪个工具
  2. 答案生成：LLM 根据工具结果生成最终答案
- 实时显示详细的日志信息

**test_query_users.py**
- 8 个测试用例覆盖所有查询场景
- 直接测试 query_users 函数
- 验证各种查询参数的正确性

---

## 🛠 技术栈

### 后端技术
- **Python 3.x**: 主编程语言
- **MCP (Model Context Protocol)**: 工具调用协议
- **FastMCP**: MCP 服务器框架
- **Pydantic**: 数据验证和类型检查

### LLM 技术
- **Ollama**: 本地 LLM 运行时
- **qwen3:14b**: 通义千问 3 大模型（14B 参数）
- **OpenAI API**: Ollama 兼容的 API 接口

### 通信协议
- **JSON-RPC 2.0**: 消息格式
- **stdio**: 传输方式（标准输入输出）

---

## 🐍 Python 库详解

### 核心依赖

**1. mcp (>=1.0.0)**
- **作用**: Model Context Protocol 的 Python SDK
- **功能**: 
  - 定义和管理 MCP 协议的通信
  - 服务器端工具注册和请求处理
  - 客户端与服务器的交互
- **在项目中的应用**: 
  - `mcp_server.py` 中用 FastMCP 启动服务器
  - `client.py` 中用 StdioClient 连接服务器

**2. openai (>=1.0.0)**
- **作用**: OpenAI API 兼容的客户端库
- **功能**:
  - 与 Ollama 本地模型通信（Ollama 提供 OpenAI 兼容 API）
  - 发送聊天请求到大模型
  - 处理流式和非流式响应
- **在项目中的应用**: `client.py` 中与 qwen3:14b 模型通信
- **使用示例**:
  ```python
  from openai import OpenAI
  client = OpenAI(
      api_key="sk-xxx",
      base_url="http://localhost:11434/v1"
  )
  response = client.chat.completions.create(
      model="qwen3:14b",
      messages=[...],
      temperature=0
  )
  ```

**3. pydantic (>=2.0.0)**
- **作用**: Python 数据验证和类型检查库
- **功能**:
  - 数据模型定义和验证
  - 自动类型转换和强制检查
  - 生成 JSON Schema（用于 MCP 工具定义）
- **在项目中的应用**:
  - `mcp_server.py` 中定义 `QueryUsersParams` 和 `QueryUsersResult`
  - 自动验证 MCP 工具参数类型
  - `client.py` 中的类型提示
- **使用示例**:
  ```python
  from pydantic import BaseModel, Field
  class QueryUsersParams(BaseModel):
      name: Optional[str] = None
      min_age: Optional[int] = None
      max_age: Optional[int] = None
  ```

### 标准库使用

**asyncio**
- **用途**: 异步编程支持
- **在项目中的应用**: MCP 工具函数都是 async 函数，支持并发处理

**typing**
- **用途**: 类型提示和类型检查
- **在项目中的应用**: 所有函数和变量都有类型注解

**json**
- **用途**: JSON 序列化和反序列化
- **在项目中的应用**: 处理 MCP 消息格式和 LLM 响应

**pathlib**
- **用途**: 跨平台路径处理
- **在项目中的应用**: 操作日志文件路径

**sys**
- **用途**: 系统相关功能
- **在项目中的应用**: 
  - 将日志输出到 stderr（避免干扰 stdio 协议）
  - 标准输出和错误流管理

**shutil**
- **用途**: 高级文件和文件夹操作
- **在项目中的应用**: 获取终端窗口尺寸用于美化输出

---

## 📦 安装和运行

### 前置条件

1. **Python 3.8+（推荐 3.10+）**
   ```bash
   python --version
   ```
   - 支持 Python 3.8、3.9、3.10、3.11、3.12
   - 推荐使用 Python 3.10 或更高版本以获得更好的性能
   - 需要 pip 包管理工具（通常与 Python 一起安装）

2. **安装 Ollama**
   - 访问 https://ollama.ai 下载安装
   - 下载 qwen3:14b 模型：
     ```bash
     ollama pull qwen3:14b
     ```
   - 启动 Ollama 服务：
     ```bash
     ollama serve
     ```
     Ollama 会在 `http://localhost:11434` 启动服务

### 安装依赖

```bash
# 创建虚拟环境
python -m venv venv

# 激活虚拟环境
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# 安装依赖
pip install -r requirements.txt
```

### 运行应用

**第一步：启动 MCP 服务器**

打开第一个终端，运行：
```bash
python mcp_server.py
```

你会看到类似的输出：
```
=========================================================================================
                                    MCP 服务器启动
=========================================================================================

已加载 13 个用户数据

工作原理:
  1. 服务器使用 stdio (标准输入输出) 协议通信
  2. 保持运行状态，等待客户端通过 stdin 发送请求
  3. 每次客户端调用工具时，解析请求参数并执行查询
  4. 执行完毕后返回 JSON 格式结果

可用工具:
  • query_users - 根据多条件查询用户
  • get_user_by_id - 根据ID获取单个用户

                             MCP 服务器就绪，等待客户端连接...
=========================================================================================
```

**第二步：启动客户端（新终端）**

打开第二个终端，运行：
```bash
python client.py
```

然后开始输入问题进行查询。

---

## 🎯 功能介绍

### query_users 工具 - 多条件用户查询

支持以下 6 种查询参数，可自由组合：

| 参数 | 类型 | 说明 |
|------|------|------|
| `name` | 字符串 | 按姓名模糊查询（不区分大小写） |
| `min_age` | 整数 | 最小年龄（包含边界，即 >= min_age） |
| `max_age` | 整数 | 最大年龄（包含边界，即 <= max_age） |
| `age_greater_than` | 整数 | 年龄大于（不包含边界，即 > age_greater_than） |
| `age_less_than` | 整数 | 年龄小于（不包含边界，即 < age_less_than） |
| `email_contains` | 字符串 | 邮箱包含的字符串（模糊匹配） |

### get_user_by_id 工具 - 按 ID 获取用户

通过用户 ID 快速获取单个用户的完整信息。

---

## 💡 使用示例

### 示例 1: 查询年龄大于 30 的用户

**输入：**
```
你: 有哪些age大于30的用户
```

**完整交互流程日志：**

```
======================================================================
[发给 LLM 的原始请求文本 #1 - 工具决策]
======================================================================
System: 你是一个智能助手，可以帮助用户查询用户数据库。
        
可用的工具：
1. query_users - 根据条件查询多个用户
   参数：
   - name: 按姓名模糊查询（可选，字符串类型）
   - min_age: 最小年龄，包含边界，即 >= min_age（可选，整数类型，如30）
   - max_age: 最大年龄，包含边界，即 <= max_age（可选，整数类型，如35）
   - age_greater_than: 年龄大于，不包含边界，即 > age_greater_than（可选，整数类型，如30）
   - age_less_than: 年龄小于，不包含边界，即 < age_less_than（可选，整数类型，如25）
   - email_contains: 邮箱包含的字符串（可选，字符串类型）

2. get_user_by_id - 根据ID获取单个用户
   参数：
   - user_id: 用户ID（必需，整数类型）

当用户询问用户信息时，你应该：
1. 分析用户的问题，判断需要哪个工具
2. 提取相关参数，注意参数类型必须正确（整数类型的字段不要使用字符串）
3. 以严格的 JSON 格式返回工具调用信息

User: 有哪些age大于30的用户

======================================================================

🤖 [来自 LLM 的原始响应文本 #1]:
{
  "tool": "query_users",
  "arguments": {
    "age_greater_than": 30
  }
}

======================================================================
[13:44:06] LLM 决策完成 (耗时: 24.24秒)

[工具调用] query_users
[工具参数] {'age_greater_than': 30}
[13:44:06] 开始调用 MCP 工具
[13:44:06] 工具调用完成 (耗时: 0.57秒)
[工具结果] {'status': 'success', 'count': 4, 'users': [
  {'id': 3, 'name': 'Charlie', 'email': 'charlie@example.com', 'age': 35},
  {'id': 5, 'name': 'Emma', 'email': 'emma.johnson@example.com', 'age': 32},
  {'id': 7, 'name': 'Grace', 'email': 'grace.lee@example.com', 'age': 31},
  {'id': 10, 'name': 'Jack', 'email': 'jack.taylor@example.com', 'age': 33}
]}

[13:44:06] 向 LLM 请求生成最终回答

======================================================================
[发给 LLM 的原始请求文本 #2 - 最终回答生成]
======================================================================
System: 你是一个智能助手，根据工具返回的数据回答用户问题。

回答要求：
- 使用简洁清晰的中文回答
- 不要使用任何 markdown 语法（如 **加粗**、## 标题、- 列表等）
- 不要输出代码块或代码段
- 直接输出纯文本答案，便于终端显示

User: 问题: 有哪些age大于30的用户
工具结果: {
  "status": "success",
  "count": 4,
  "users": [
    {"id": 3, "name": "Charlie", "email": "charlie@example.com", "age": 35},
    {"id": 5, "name": "Emma", "email": "emma.johnson@example.com", "age": 32},
    {"id": 7, "name": "Grace", "email": "grace.lee@example.com", "age": 31},
    {"id": 10, "name": "Jack", "email": "jack.taylor@example.com", "age": 33}
  ]
}

======================================================================
[13:44:28] 最终回答生成完成 (耗时: 21.87秒)
[总耗时] 46.69秒

🤖 AI 发给用户的回答: 共有4位年龄大于30的用户：
1、Charlie（35岁，邮箱：charlie@example.com）
2、Emma（32岁，邮箱：emma.johnson@example.com）
3、Grace（31岁，邮箱：grace.lee@example.com）
4、Jack（33岁，邮箱：jack.taylor@example.com）
```

### 示例 2: 其他可能的查询

```
你: 名字中包含"David"且年龄在25到30岁之间的用户有谁

你: 邮箱包含"smith"的用户是谁

你: 查询用户ID为5的信息

你: 年龄小于25岁的用户有多少个
```

---

## 📊 服务器日志示例

服务器启动时输出：

```
=========================================================================================
                                    MCP 服务器启动
=========================================================================================

已加载 13 个用户数据

工作原理:
  1. 服务器使用 stdio (标准输入输出) 协议通信
  2. 保持运行状态，等待客户端通过 stdin 发送请求
  3. 每次客户端调用工具时，解析请求参数并执行查询
  4. 执行完毕后返回 JSON 格式结果

可用工具:
  • query_users - 根据多条件查询用户
  • get_user_by_id - 根据ID获取单个用户

                             MCP 服务器就绪，等待客户端连接...
=========================================================================================
```

---

## 🔄 工作流程

### 两步式 LLM 处理流程

```
用户输入问题
    ↓
[第一步] 工具决策
    - LLM 分析问题
    - 确定调用哪个工具
    - 提取相关参数
    - 返回 JSON 格式的工具调用
    ↓
[工具执行]
    - MCP 客户端执行工具
    - 数据库返回结果
    ↓
[第二步] 答案生成
    - LLM 根据工具结果
    - 生成用户友好的最终答案
    ↓
最终答案展示给用户
```

### 日志记录

每个查询都会生成详细的日志，包括：
- ✅ 接收到的用户问题
- ✅ LLM 的工具决策过程
- ✅ 发送给 LLM 的完整提示词
- ✅ LLM 的原始响应
- ✅ 工具的执行参数和结果
- ✅ 最终生成的答案
- ✅ 整个流程的耗时统计

---

## 🧪 测试

运行单元测试验证所有查询功能：

```bash
python test_query_users.py
```

测试覆盖内容：
- 查询所有用户
- 按姓名查询
- 按年龄范围查询（包含边界）
- 按邮箱查询
- 组合条件查询
- 年龄大于查询（不包含边界）
- 年龄小于查询（不包含边界）
- 年龄区间查询（排他性边界）

---

## 🎓 学习重点

这个项目适合学习以下内容：

1. **MCP 协议的实现**：了解如何定义和调用工具
2. **LLM 集成**：如何将本地大模型与应用集成
3. **两阶段 LLM 处理**：工具决策和结果理解
4. **JSON-RPC 通信**：stdio 协议的使用
5. **异步编程**：async/await 在 MCP 中的应用
6. **日志系统**：完整的运行日志记录
7. **数据验证**：Pydantic 模型的使用

---

## 📝 Python 版本和依赖列表

### Python 版本要求

| Python 版本 | 支持情况 | 推荐度 |
|-----------|--------|--------|
| 3.8 | ✅ 支持 | ⭐ 最低版本 |
| 3.9 | ✅ 支持 | ⭐⭐ |
| 3.10 | ✅ 支持 | ⭐⭐⭐ 推荐 |
| 3.11 | ✅ 支持 | ⭐⭐⭐ 推荐 |
| 3.12 | ✅ 支持 | ⭐⭐⭐⭐ 最新稳定 |

### 项目依赖

```txt
mcp>=1.0.0              # Model Context Protocol SDK - MCP 协议支持
openai>=1.0.0           # OpenAI 兼容 API - 与 Ollama 通信
pydantic>=2.0.0         # 数据验证和类型检查 - 参数验证和类型强制
```

### 安装依赖详解

创建 `requirements.txt` 文件内容如上，然后执行：

```bash
pip install -r requirements.txt
```

也可以分别安装：

```bash
pip install mcp>=1.0.0
pip install openai>=1.0.0
pip install pydantic>=2.0.0
```

**版本选择建议：**
- 使用 `mcp>=1.0.0` 确保获得最新的 MCP 协议支持
- 使用 `openai>=1.0.0` 兼容 Ollama 的 OpenAI API
- 使用 `pydantic>=2.0.0` 获得性能改进和新功能

---

## 🚀 扩展方向

可以基于这个项目进行以下扩展：

- 🔌 **集成更多工具**：添加其他数据库、API 调用等
- 💾 **持久化存储**：使用真实数据库替代内存数据
- 🔐 **权限控制**：添加用户认证和授权
- 📈 **性能优化**：缓存、并发处理等
- 🌍 **多语言支持**：支持英文、日文等多种语言
- 🎨 **Web 界面**：创建 Web UI 进行交互
- 📊 **数据分析**：添加更复杂的查询和分析功能

---

## 📄 许可证

MIT License
