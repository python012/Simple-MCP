"""
MCP å®¢æˆ·ç«¯ - ä¸é˜¿é‡Œäº‘ Qwen å’Œ MCP æœåŠ¡å™¨äº¤äº’
ä½¿ç”¨è‡ªç„¶è¯­è¨€æŸ¥è¯¢ç”¨æˆ·æ•°æ®åº“
"""

import asyncio
import json
import os
from typing import Dict, Any

from openai import OpenAI
import httpx
from dotenv import load_dotenv

# å¯¼å…¥ MCP å®¢æˆ·ç«¯åº“
from mcp.client.stdio import stdio_client, StdioServerParameters
from mcp.client.session import ClientSession
from mcp.types import TextContent

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# 1. é…ç½®
QWEN_MODEL = "qwen-flash"

# ä¼˜å…ˆä½¿ç”¨ ALIYUN_MODEL_API_KEYï¼Œå…¶æ¬¡å…¼å®¹ OPENAI_API_KEY ç¯å¢ƒå˜é‡
_api_key = os.getenv("ALIYUN_MODEL_API_KEY") or os.getenv("OPENAI_API_KEY")

# ä½¿ç”¨è‡ªå®šä¹‰ httpx.Client å…³é—­ç³»ç»Ÿä»£ç†ï¼Œé¿å…æ¡æ‰‹è¶…æ—¶
_http_client = httpx.Client(
    trust_env=False,  # å¿½ç•¥ç³»ç»Ÿç¯å¢ƒä»£ç†/è¯ä¹¦è®¾ç½®
    timeout=httpx.Timeout(connect=30.0, read=60.0, write=30.0, pool=30.0),
)

client = OpenAI(
    api_key=_api_key,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    max_retries=3,
    http_client=_http_client,
)


async def call_mcp_tool(tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
    """
    è°ƒç”¨ MCP æœåŠ¡å™¨çš„å·¥å…·

    Args:
        tool_name: å·¥å…·åç§°
        arguments: å·¥å…·å‚æ•°

    Returns:
        å·¥å…·æ‰§è¡Œç»“æœ
    """
    # é…ç½® MCP æœåŠ¡å™¨å‚æ•°
    server_params = StdioServerParameters(
        command="python",
        args=["mcp_server.py"],
    )
    
    try:
        # ä½¿ç”¨ async with ç¡®ä¿èµ„æºæ­£ç¡®ç®¡ç†
        async with stdio_client(server_params) as (read_stream, write_stream):
            async with ClientSession(read_stream, write_stream) as session:
                # åˆå§‹åŒ–è¿æ¥
                await session.initialize()
                
                # è°ƒç”¨å·¥å…·
                result = await session.call_tool(tool_name, arguments)
                
                # æå–å·¥å…·è¿”å›çš„å†…å®¹
                if hasattr(result, 'content') and result.content:
                    # è·å–ç¬¬ä¸€ä¸ªæ–‡æœ¬å†…å®¹
                    for content_item in result.content:
                        if isinstance(content_item, TextContent):
                            content_text = content_item.text
                            # å°è¯•è§£æ JSON
                            try:
                                return json.loads(content_text)
                            except:
                                return {"result": content_text}
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬å†…å®¹
                    return {"result": str(result)}
                else:
                    return {"result": str(result)}
                    
    except Exception as e:
        print(f"âŒ è°ƒç”¨å·¥å…·æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return {"error": str(e)}


class NaturalLanguageQuery:
    """è‡ªç„¶è¯­è¨€æŸ¥è¯¢å¤„ç†å™¨"""

    def __init__(self):
        pass

    async def _get_tool_decision(self, question: str) -> str:
        """
        è®© LLM å†³å®šæ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·ä»¥åŠå¦‚ä½•è°ƒç”¨

        Args:
            question: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€é—®é¢˜

        Returns:
            åŒ…å«å·¥å…·è°ƒç”¨å†³ç­–çš„ JSON å­—ç¬¦ä¸²
        """
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æŸ¥è¯¢ç”¨æˆ·æ•°æ®åº“ã€‚
        
å¯ç”¨çš„å·¥å…·ï¼š
1. query_users - æ ¹æ®æ¡ä»¶æŸ¥è¯¢å¤šä¸ªç”¨æˆ·
   å‚æ•°ï¼š
   - name: æŒ‰å§“åæ¨¡ç³ŠæŸ¥è¯¢ï¼ˆå¯é€‰ï¼‰
   - min_age: æœ€å°å¹´é¾„ï¼ˆå¯é€‰ï¼‰
   - max_age: æœ€å¤§å¹´é¾„ï¼ˆå¯é€‰ï¼‰
   - email_contains: é‚®ç®±åŒ…å«çš„å­—ç¬¦ä¸²ï¼ˆå¯é€‰ï¼‰

2. get_user_by_id - æ ¹æ®IDè·å–å•ä¸ªç”¨æˆ·
   å‚æ•°ï¼š
   - user_id: ç”¨æˆ·IDï¼ˆå¿…éœ€ï¼‰

å½“ç”¨æˆ·è¯¢é—®ç”¨æˆ·ä¿¡æ¯æ—¶ï¼Œä½ åº”è¯¥ï¼š
1. åˆ†æç”¨æˆ·çš„é—®é¢˜ï¼Œåˆ¤æ–­éœ€è¦å“ªä¸ªå·¥å…·
2. æå–ç›¸å…³å‚æ•°
3. ä»¥ä¸¥æ ¼çš„ JSON æ ¼å¼è¿”å›å·¥å…·è°ƒç”¨ä¿¡æ¯

JSON æ ¼å¼ï¼š
{
  "tool": "å·¥å…·åç§°",
  "arguments": {
    "å‚æ•°1": "å€¼1",
    "å‚æ•°2": "å€¼2"
  }
}

å¦‚æœé—®é¢˜ä¸éœ€è¦æŸ¥è¯¢æ•°æ®åº“ï¼Œç›´æ¥å›ç­”é—®é¢˜ï¼Œä¸è¦è¿”å› JSONã€‚
"""

        response = client.chat.completions.create(
            model=QWEN_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": question}
            ],
            # DashScope å…¼å®¹æ¨¡å¼å¯èƒ½ä¸æ”¯æŒ response_formatï¼Œæ”¹ä¸ºé€šè¿‡æç¤ºçº¦æŸ
            temperature=0,
        )

        return response.choices[0].message.content or ""

    async def query(self, question: str) -> str:
        """
        å¤„ç†è‡ªç„¶è¯­è¨€æŸ¥è¯¢

        Args:
            question: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€é—®é¢˜

        Returns:
            AI ç”Ÿæˆçš„å›ç­”
        """
        try:
            # ç¬¬ä¸€æ­¥ï¼šè®© LLM å†³å®šæ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
            tool_decision_str = await self._get_tool_decision(question)
            print(f"ğŸ§  LLM å†³ç­–: {tool_decision_str}")

            # å°è¯•è§£æ JSON
            try:
                tool_decision = json.loads(tool_decision_str)

                # æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯
                if "tool" in tool_decision and "arguments" in tool_decision:
                    tool_name = tool_decision["tool"]
                    arguments = tool_decision["arguments"]

                    print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
                    print(f"ğŸ“Š å·¥å…·å‚æ•°: {arguments}")

                    # è°ƒç”¨ MCP å·¥å…·
                    tool_result = await call_mcp_tool(tool_name, arguments)
                    print(f"âœ… å·¥å…·ç»“æœ: {tool_result}")

                    # ç¬¬äºŒæ­¥ï¼šè®© LLM æ ¹æ®å·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›ç­”
                    final_response = client.chat.completions.create(
                        model=QWEN_MODEL,
                        messages=[
                            {
                                "role": "system",
                                "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œæ ¹æ®å·¥å…·è¿”å›çš„æ•°æ®å›ç­”ç”¨æˆ·é—®é¢˜ã€‚ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œæ ¼å¼æ¸…æ™°ã€‚",
                            },
                            {
                                "role": "user",
                                "content": f"é—®é¢˜: {question}\nå·¥å…·ç»“æœ: {json.dumps(tool_result, ensure_ascii=False, indent=2)}",
                            },
                        ],
                        temperature=0.2,
                    )
                    return final_response.choices[0].message.content or ""

            except json.JSONDecodeError:
                # ä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œç›´æ¥è¿”å› LLM çš„å›ç­”
                pass

            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å› LLM çš„å›ç­”
            return tool_decision_str

        except Exception as e:
            return f"âŒ å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}"


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ’¬ æ™ºèƒ½ç”¨æˆ·æŸ¥è¯¢åŠ©æ‰‹ (MCP + é˜¿é‡Œäº‘ Qwen)")
    print("âœ… å·²è¿æ¥åˆ°é˜¿é‡Œäº‘ Qwen (qwen-flash)")
    print("â“ è¾“å…¥ä½ çš„é—®é¢˜ï¼Œè¾“å…¥ 'exit' é€€å‡º")
    print("-" * 50)

    # åˆ›å»ºæŸ¥è¯¢å¤„ç†å™¨
    query_processor = NaturalLanguageQuery()

    while True:
        question = input("\nğŸ‘¤ ä½ : ")
        if question.lower() == "exit":
            break

        print("ğŸ¤– AI æ€è€ƒä¸­...", end="", flush=True)

        try:
            # å¤„ç†æŸ¥è¯¢
            answer = await query_processor.query(question)
            print(f"\nğŸ¤– AI: {answer}")
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
